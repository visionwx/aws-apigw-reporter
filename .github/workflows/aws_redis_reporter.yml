name: AWS_REDIS_REPORTER

# on:
#     workflow_dispatch:
#     schedule:
#       - cron:  '20 1 * * *'

on:
  push:
    branches: [ dev_bob ]

env:
    AWS_S3_KEY_ID: ${{ secrets.AWS_S3_KEY_ID }}
    AWS_S3_KEY_SECRET: ${{ secrets.AWS_S3_KEY_SECRET }}
    AWS_S3_BUCKET_NAME: boom2-resource
    AWS_S3_COMPONENT_BUCKET_NAME: trickle-component
    AWS_S3_REGION: us-east-1
    AWS_CLOUD_FRONT_DISTRIBUTION_ID: E28OIAI99C3YGA
    AWS_DEPLOY_KEY: ${{ secrets.AWS_DEPLOY_KEY }}
    AWS_DEPLOY_SECRET: ${{ secrets.AWS_DEPLOY_SECRET }}
    AWS_LAMBDA_FUNCTION_NAME: trickle_ssr_dev
    ECR_REGISTRY: 257417524232.dkr.ecr.us-east-1.amazonaws.com
    IMAGE_NAME: trickle-ssr
    AWS_DEFAULT_REGION: us-east-1
    AWS_LAMBDA_EDGE_FUNCTION_NAME: trickle_edge_dev
    AWS_S3_LAMBDA_PACKAGE_BUCKET_NAME: lambda-package-20220712
    TRICKLE_WORKSPACE_ID: "30788161542029315"
    TRICKLE_MEMBER_ID: "422649524830339077"
    TRICKLE_CHANNEL_ID: "614087579146387462"
    LBD_TRICKLE_APP: trickle-app-lambda-live
    LBD_TRICKLE_ASYNC: trickle_async_handler_live
    LBD_SOCKET_APP: socket_service_live
    LBD_SOCKET_SEND: SEND_SOCKET_MESSAGE_LIVE
    LBD_BAAS_APP: baas-vc-async-handler-live
    LBD_BAAS_ASYNC: baas-vc-app-handler-live
    LBD_PERIOD: 900
    MYSQL_NAME: trickle

jobs:

    redis_curconnections:
        name: redis_curconnections
        runs-on: ubuntu-latest
        outputs:
          reportUrl: ${{ steps.upload.outputs.reportUrl }}
        steps:
            # Pull Code
            - name: Pull repo
              uses: actions/checkout@v2

            # Configure AWS S3
            - name: Configure AWS credentials
              uses: aws-actions/configure-aws-credentials@v1
              with:
                  aws-access-key-id: ${{ env.AWS_DEPLOY_KEY }}
                  aws-secret-access-key: ${{ env.AWS_DEPLOY_SECRET }}
                  aws-region: ${{ env.AWS_S3_REGION }}
            
            # Get last day
            - name: Get last day
              id: get-date
              run: |
                date -d "1 day ago" +"%Y-%m-%d"

            # Send Query Request
            - name: Send query reuqest
              id: query
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                cdate=`date +"%Y-%m-%d"`
                rm -rf outs
                mkdir outs
                mkdir -p outs/$ldate/redis_curconnections
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name CurrConnections \
                  --statistics Maximum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-001 > outs/kvstore_01_connections.json
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name CurrConnections \
                  --statistics Maximum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-002 > outs/kvstore_02_connections.json
                python3 parse_lambda_stats.py -f outs -p ${{ env.LBD_PERIOD }} -t 'MaximumConnections(Counts)' -m Maximum
                cp outs.json lines.html.json
                cp lines.html outs/$ldate/redis_curconnections
                cp lines.html.json outs/$ldate/redis_curconnections
            
            # Upload report
            - name: Upload report
              id: upload
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                aws s3 sync outs/$ldate/redis_curconnections s3://${{ env.AWS_S3_BUCKET_NAME }}/miniapps/$ldate/redis_curconnections
                reportUrl=https://devres.trickle.so/miniapps/$ldate/redis_curconnections/lines.html
                echo "::set-output name=reportUrl::$reportUrl"

    redis_cacherate:
        name: redis_cacherate
        runs-on: ubuntu-latest
        outputs:
          reportUrl: ${{ steps.upload.outputs.reportUrl }}
        steps:
            # Pull Code
            - name: Pull repo
              uses: actions/checkout@v2

            # Configure AWS S3
            - name: Configure AWS credentials
              uses: aws-actions/configure-aws-credentials@v1
              with:
                  aws-access-key-id: ${{ env.AWS_DEPLOY_KEY }}
                  aws-secret-access-key: ${{ env.AWS_DEPLOY_SECRET }}
                  aws-region: ${{ env.AWS_S3_REGION }}
            
            # Get last day
            - name: Get last day
              id: get-date
              run: |
                date -d "1 day ago" +"%Y-%m-%d"

            # Send Query Request
            - name: Send query reuqest
              id: query
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                cdate=`date +"%Y-%m-%d"`
                rm -rf outs
                mkdir outs
                mkdir -p outs/$ldate/redis_cacherate
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name CacheHitRate \
                  --statistics Average \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-001 > outs/kvstore_01_cacheHitRate.json
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name CacheHitRate \
                  --statistics Average \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-002 > outs/kvstore_02_cacheHitRate.json
                python3 parse_lambda_stats.py -f outs -p ${{ env.LBD_PERIOD }} -t 'CacheHiteRate(Percent)' -m Average
                cp outs.json lines.html.json
                cp lines.html outs/$ldate/redis_cacherate
                cp lines.html.json outs/$ldate/redis_cacherate
            
            # Upload report
            - name: Upload report
              id: upload
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                aws s3 sync outs/$ldate/redis_cacherate s3://${{ env.AWS_S3_BUCKET_NAME }}/miniapps/$ldate/redis_cacherate
                reportUrl=https://devres.trickle.so/miniapps/$ldate/redis_cacherate/lines.html
                echo "::set-output name=reportUrl::$reportUrl"

    redis_cpu:
        name: redis_cpu
        runs-on: ubuntu-latest
        outputs:
          reportUrl: ${{ steps.upload.outputs.reportUrl }}
        steps:
            # Pull Code
            - name: Pull repo
              uses: actions/checkout@v2

            # Configure AWS S3
            - name: Configure AWS credentials
              uses: aws-actions/configure-aws-credentials@v1
              with:
                  aws-access-key-id: ${{ env.AWS_DEPLOY_KEY }}
                  aws-secret-access-key: ${{ env.AWS_DEPLOY_SECRET }}
                  aws-region: ${{ env.AWS_S3_REGION }}
            
            # Get last day
            - name: Get last day
              id: get-date
              run: |
                date -d "1 day ago" +"%Y-%m-%d"

            # Send Query Request
            - name: Send query reuqest
              id: query
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                cdate=`date +"%Y-%m-%d"`
                rm -rf outs
                mkdir outs
                mkdir -p outs/$ldate/redis_cpu
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name CPUUtilization \
                  --statistics Maximum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-001 > outs/kvstore_01_cpu.json
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name CPUUtilization \
                  --statistics Maximum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-002 > outs/kvstore_02_cacheHitRate.json
                python3 parse_lambda_stats.py -f outs -p ${{ env.LBD_PERIOD }} -t 'CacheHiteRate(Percent)' -m Maximum
                cp outs.json lines.html.json
                cp lines.html outs/$ldate/redis_cpu
                cp lines.html.json outs/$ldate/redis_cpu
            
            # Upload report
            - name: Upload report
              id: upload
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                aws s3 sync outs/$ldate/redis_cpu s3://${{ env.AWS_S3_BUCKET_NAME }}/miniapps/$ldate/redis_cpu
                reportUrl=https://devres.trickle.so/miniapps/$ldate/redis_cpu/lines.html
                echo "::set-output name=reportUrl::$reportUrl"

    redis_memory:
        name: redis_memory
        runs-on: ubuntu-latest
        outputs:
          reportUrl: ${{ steps.upload.outputs.reportUrl }}
        steps:
            # Pull Code
            - name: Pull repo
              uses: actions/checkout@v2

            # Configure AWS S3
            - name: Configure AWS credentials
              uses: aws-actions/configure-aws-credentials@v1
              with:
                  aws-access-key-id: ${{ env.AWS_DEPLOY_KEY }}
                  aws-secret-access-key: ${{ env.AWS_DEPLOY_SECRET }}
                  aws-region: ${{ env.AWS_S3_REGION }}
            
            # Get last day
            - name: Get last day
              id: get-date
              run: |
                date -d "1 day ago" +"%Y-%m-%d"

            # Send Query Request
            - name: Send query reuqest
              id: query
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                cdate=`date +"%Y-%m-%d"`
                rm -rf outs
                mkdir outs
                mkdir -p outs/$ldate/redis_memory
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name DatabaseMemoryUsagePercentage \
                  --statistics Maximum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-001 > outs/kvstore_01_memoryUage.json
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name DatabaseMemoryUsagePercentage \
                  --statistics Maximum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-002 > outs/kvstore_02_memoryUage.json
                python3 parse_lambda_stats.py -f outs -p ${{ env.LBD_PERIOD }} -t 'MemoryUsage(Percent)' -m Maximum
                cp outs.json lines.html.json
                cp lines.html outs/$ldate/redis_memory
                cp lines.html.json outs/$ldate/redis_memory
            
            # Upload report
            - name: Upload report
              id: upload
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                aws s3 sync outs/$ldate/redis_memory s3://${{ env.AWS_S3_BUCKET_NAME }}/miniapps/$ldate/redis_memory
                reportUrl=https://devres.trickle.so/miniapps/$ldate/redis_memory/lines.html
                echo "::set-output name=reportUrl::$reportUrl"

    redis_traffic:
        name: redis_traffic
        runs-on: ubuntu-latest
        outputs:
          reportUrl: ${{ steps.upload.outputs.reportUrl }}
        steps:
            # Pull Code
            - name: Pull repo
              uses: actions/checkout@v2

            # Configure AWS S3
            - name: Configure AWS credentials
              uses: aws-actions/configure-aws-credentials@v1
              with:
                  aws-access-key-id: ${{ env.AWS_DEPLOY_KEY }}
                  aws-secret-access-key: ${{ env.AWS_DEPLOY_SECRET }}
                  aws-region: ${{ env.AWS_S3_REGION }}
            
            # Get last day
            - name: Get last day
              id: get-date
              run: |
                date -d "1 day ago" +"%Y-%m-%d"

            # Send Query Request
            - name: Send query reuqest
              id: query
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                cdate=`date +"%Y-%m-%d"`
                rm -rf outs
                mkdir outs
                mkdir -p outs/$ldate/redis_traffic

                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name NetworkBytesIn \
                  --statistics Sum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-001 > outs/kvstore_01_trafficIn.json
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name NetworkBytesIn \
                  --statistics Sum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-002 > outs/kvstore_02_trafficIn.json
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name NetworkBytesOut \
                  --statistics Sum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-001 > outs/kvstore_01_trafficOut.json
                aws cloudwatch get-metric-statistics \
                  --namespace AWS/ElastiCache \
                  --metric-name NetworkBytesOut \
                  --statistics Sum \
                  --start-time ${ldate}T00:00:00 \
                  --end-time ${cdate}T00:00:00 \
                  --period ${{ env.LBD_PERIOD }} \
                  --dimensions Name=CacheClusterId,Value=trickle-kv-store-002 > outs/kvstore_02_trafficOut.json                  
                python3 parse_lambda_stats.py -mf 0.000001 -f outs -p ${{ env.LBD_PERIOD }} -t 'TrafficStats(MB)' -m Sum
                cp outs.json lines.html.json
                cp lines.html outs/$ldate/redis_traffic
                cp lines.html.json outs/$ldate/redis_traffic
            
            # Upload report
            - name: Upload report
              id: upload
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                aws s3 sync outs/$ldate/redis_traffic s3://${{ env.AWS_S3_BUCKET_NAME }}/miniapps/$ldate/redis_traffic
                reportUrl=https://devres.trickle.so/miniapps/$ldate/redis_traffic/lines.html
                echo "::set-output name=reportUrl::$reportUrl"

    send-trickle:
        name: send-trickle
        runs-on: ubuntu-latest
        needs: [redis_curconnections,redis_cacherate,redis_cpu,redis_memory,redis_traffic]
        steps:
            # Get last day
            - name: Get last day
              id: getdate
              run: |
                ldate=`date -d "1 day ago" +"%Y-%m-%d"`
                echo "::set-output name=ldate::$ldate"

            # Send trickle
            - name: Send trickle
              uses: visionwx/trickle-sender@v1.0.4
              with:
                trickleToken: ${{ secrets.trickleToken }}
                workspaceId: ${{ env.TRICKLE_WORKSPACE_ID }}
                memberId: ${{ env.TRICKLE_MEMBER_ID }}
                channelId: ${{ env.TRICKLE_CHANNEL_ID }}
                blockType: trickle
                blockData: '[{"type":"h2","value":"AWS Rdis Report for ${{ steps.getdate.outputs.ldate }}"},{"type":"text","value":""},{"type":"embed","value":"${{ needs.redis_curconnections.outputs.reportUrl }}"},{"type":"text","value":""},{"type":"embed","value":"${{ needs.redis_cacherate.outputs.reportUrl }}"},{"type":"text","value":""},{"type":"embed","value":"${{ needs.redis_cpu.outputs.reportUrl }}"},{"type":"text","value":""},{"type":"embed","value":"${{ needs.redis_memory.outputs.reportUrl }}"},{"type":"text","value":""},{"type":"embed","value":"${{ needs.redis_traffic.outputs.reportUrl }}"}]'
